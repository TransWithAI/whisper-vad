[project]
name = "whisper-vad"
version = "0.1.0"
description = "Fine-tuning Whisper for Voice Activity Detection"
readme = "README.md"
requires-python = ">=3.13"
authors = [
    { name = "Your Name", email = "your.email@example.com" }
]
keywords = ["whisper", "vad", "voice-activity-detection", "pytorch", "audio"]
classifiers = [
    "Development Status :: 3 - Alpha",
    "Intended Audience :: Science/Research",
    "License :: OSI Approved :: MIT License",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.13",
    "Topic :: Scientific/Engineering :: Artificial Intelligence",
]

dependencies = [
    # Core dependencies
    "torch>=2.0.0",
    "torchaudio>=2.0.0",
    "pytorch-lightning>=2.0.0",
    "transformers>=4.30.0",
    "datasets>=2.14.0",
    # Audio processing
    "librosa>=0.10.0",
    "soundfile>=0.12.0",
    "torchcodec>=0.0.1",
    # Scientific computing
    "numpy>=1.24.0",
    "scipy>=1.10.0",
    "scikit-learn>=1.3.0",
    # Visualization and logging
    "tensorboard>=2.14.0",
    "wandb>=0.15.0",
    "matplotlib>=3.7.0",
    "rich>=13.0.0",
    # Configuration
    "PyYAML>=6.0",
]

[project.optional-dependencies]
dev = [
    "pytest>=7.4.0",
    "pytest-cov>=4.1.0",
    "black>=23.0.0",
    "ruff>=0.1.0",
    "mypy>=1.5.0",
    "pre-commit>=3.3.0",
]
accelerate = [
    "accelerate>=0.20.0",
    "deepspeed>=0.10.0",
]
onnx = [
    "onnxruntime>=1.17.0",  # CPU inference
    "onnxscript",  # ONNX model export and manipulation
]
onnx-gpu = [
    "onnxruntime-gpu>=1.17.0",  # GPU inference (includes CPU support)
    "onnxscript",  # ONNX model export and manipulation
]

[project.scripts]
whisper-vad-train = "train:main"
whisper-vad-inference = "inference:main"

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[dependency-groups]
dev = [
    "ipykernel>=6.25.0",
    "jupyter>=1.0.0",
    "notebook>=7.0.0",
]

[tool.uv.pip]
# UV-specific pip settings
index-url = "https://pypi.org/simple"
extra-index-url = ["https://download.pytorch.org/whl/cu121"]  # For CUDA 12.1 PyTorch builds
find-links = []

[tool.hatch.build.targets.wheel]
packages = ["models", "utils"]

[tool.black]
line-length = 100
target-version = ["py313"]

[tool.ruff]
line-length = 100
target-version = "py313"
select = [
    "E",   # pycodestyle errors
    "W",   # pycodestyle warnings
    "F",   # pyflakes
    "I",   # isort
    "B",   # flake8-bugbear
    "C4",  # flake8-comprehensions
    "UP",  # pyupgrade
]
ignore = [
    "E501",  # line too long (handled by black)
    "B008",  # do not perform function calls in argument defaults
    "C901",  # too complex
    "W191",  # indentation contains tabs
]

[tool.ruff.isort]
known-third-party = ["torch", "transformers", "pytorch_lightning"]

[tool.mypy]
python_version = "3.13"
warn_return_any = true
warn_unused_configs = true
ignore_missing_imports = true
check_untyped_defs = true
